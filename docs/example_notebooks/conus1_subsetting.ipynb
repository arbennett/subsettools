{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cabad1e",
   "metadata": {},
   "source": [
    "# **Subset CONUS and run ParFlow**\n",
    "### This notebook has two principal sections: \n",
    "1. Subset all static inputs and climate forcings from a CONUS run stored in Hydrodata \n",
    "2. Load and alter a reference run to do a single or ensemble run of ParFlow-CLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e04ee",
   "metadata": {},
   "source": [
    "### Import the required libraries for step one (subsetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d6d7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import needed libraries to subset\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from parflow import Run\n",
    "from parflow.tools.io import read_pfb, write_pfb, read_clm, read_pfb_sequence\n",
    "from parflow.tools.fs import cp, mkdir\n",
    "from parflow.tools.settings import set_working_directory\n",
    "from subsettools.subsettools import *\n",
    "from subsettools.datasets import *\n",
    "import pathlib\n",
    "import shutil\n",
    "import xarray as xr\n",
    "import hydrodata.data_catalog.data_access\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872b0db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Define variables to access datasets to subset in Hydrodata and define write paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06301eb",
   "metadata": {},
   "source": [
    "#### We will be testing with the Upper Verde watershed for this example\n",
    "- HUC: 15060202\n",
    "- Size: 6496 km^2 (ni = 112, nj = 90)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24becc",
   "metadata": {},
   "source": [
    "#### Set your variables to specify which static and climate forcing data you would like to subset in Hydrodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9ad854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "runname = \"datacatalog_test1\"\n",
    "#provide a way to create a subset from the conus domain (huc, lat/lon bbox currently supported)\n",
    "huc_list = [\"15060202\",\"15060203\"] #example with 2 hucs\n",
    "#huc_list = [\"15060202\"] #example with 1 huc\n",
    "#provide information about the datasets you want to access for run inputs using the data catalog\n",
    "start = \"2005-10-01\" \n",
    "end = \"2006-09-30\"\n",
    "grid = \"conus1\"  \n",
    "run_ds = \"conus1_baseline_mod\"\n",
    "var_ds = \"conus1_domain\"\n",
    "forcing_ds = \"NLDAS2\"\n",
    "P = 1 #num procs in x-dir\n",
    "Q = 1 #num-procs in y-dir\n",
    "\n",
    "#Set the directory paths where you want to write your subset files\n",
    "static_write_dir = f\"{home}/subsettools_tutorial/inputs/{runname}_{grid}_{end[:4]}WY/static/\"\n",
    "mkdir(static_write_dir) \n",
    "forcing_dir = f\"{home}/subsettools_tutorial/inputs/{runname}_{grid}_{end[:4]}WY/forcing/\"\n",
    "mkdir(forcing_dir)\n",
    "\n",
    "#setting up parflow run paths and run name\n",
    "pf_out_dir = f\"{home}/subsettools_tutorial/outputs/{runname}_{grid}_{end[:4]}WY/\"\n",
    "mkdir(pf_out_dir) \n",
    "\n",
    "#set PARFLOW_DIR path to the preferred version of ParFlow\n",
    "os.environ[\"PARFLOW_DIR\"] = \"/home/SHARED/software/parflow/3.10.0\"\n",
    "\n",
    "reference_run = get_ref_yaml_path(grid, \"transient\", \"solid\")\n",
    "target_runscript = pf_out_dir + runname + '.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdc711",
   "metadata": {},
   "source": [
    "### 2. Get the desired ParFlow x/y bbox from user provided geospatial information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cad85ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ga6/.conda/envs/subsettools/lib/python3.9/site-packages/xarray/backends/plugins.py:68: RuntimeWarning: Engine 'parflow' loading failed:\n",
      "No module named 'dask'\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box: [375, 127, 502, 329]\n",
      "nj: 202\n",
      "ni: 127\n"
     ]
    }
   ],
   "source": [
    "ij_bounds = huc_to_ij(hucs = huc_list, grid = grid) #[imin, jmin, imax, jmax]\n",
    "print(f'bounding box: {ij_bounds}')\n",
    "\n",
    "nj = ij_bounds[3]-ij_bounds[1]\n",
    "ni = ij_bounds[2]-ij_bounds[0]\n",
    "print(f'nj: {nj}')\n",
    "print(f'ni: {ni}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58099778",
   "metadata": {},
   "source": [
    "### 3. Make the mask and solid file\n",
    "You only do this if you provided a huc or a shapefile where we can extract a mask from the conus tif. Otherwise, the reference run is rewritten to provide a box domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc88dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported domain boundary, only HUC IDs are supported currently to produce solid files. \n",
      "Run ParFlow with a box domain template. \n"
     ]
    }
   ],
   "source": [
    "create_mask_solid(huc_list, grid = grid, write_dir = static_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73a3a2",
   "metadata": {},
   "source": [
    "### 4. Subset the static ParFlow inputs\n",
    "Two options to subset static inputs. \n",
    "1. subset_static(): This function when provided with a variable dataset hosted on hydrodata will subset all static inputs required to do a baseline run from the default argument var_list without the user specify specific files. Pressure is the steady state pressure. If a user would like the override this, they may pass in their own value for var_list and their specifed variables in the target dataset will be subset. \n",
    "\n",
    "3. subset_press_init(): This function will write the subset pressure of the last hour in the last day before your start date. If no such pressure file exists in the hydrodata run dataset specifed, no file will be written. The function assumes UTC of zero as the default, but allows the user to override. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129657dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_static(ij_bounds, dataset = var_ds, write_dir = static_write_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_press_init(ij_bounds, dataset = run_ds, date = start, write_dir = static_write_dir, time_zone = 'UTC')\n",
    "#subset_press_init(ij_bounds, dataset = run_ds, date = start, write_dir = static_write_dir, time_zone = 'America/New_York')\n",
    "#subset_press_init(ij_bounds, dataset = run_ds, date = start, write_dir = static_write_dir, time_zone = 'US/Central')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db993d5b",
   "metadata": {},
   "source": [
    "### 5. Configure CLM drivers\n",
    "This function will get the clm drivers that are associated with your run dataset (same as data set as where you will get your initial pressure file). Vegm, vegp and drv_clmin will be written into your specified static input directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81040bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_clm(ij_bounds, start = start, end = end, dataset = run_ds, write_dir = static_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c5b8f",
   "metadata": {},
   "source": [
    "### 6. Subset the climate forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce6901",
   "metadata": {},
   "source": [
    "This function will write all variables needed to run CLM for your specified forcing dataset, on your specified grid, subset to the i/j boundary that was returned previously within the specified start and end date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_forcing(ij_bounds, grid = grid, start = start, end = end, dataset = forcing_ds, write_dir = forcing_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7e93e",
   "metadata": {},
   "source": [
    "### 7. Sanity check static and climate forcing by plotting (not an exhaustive check for accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef49df8",
   "metadata": {},
   "source": [
    "#### Check static inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b473f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(static_write_dir) \n",
    "test = read_pfb('pf_indicator.pfb')\n",
    "print(test.shape)\n",
    "\n",
    "cmap1='Reds'\n",
    "sub_flip = np.zeros((1,nj,ni))\n",
    "sub_flip[0,:,:] = test[0,:,:]\n",
    "sub_flip = np.flip(sub_flip,1)\n",
    "\n",
    "plt.imshow(sub_flip[0,:,:], cmap=cmap1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da499900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking vegm\n",
    "os.chdir(static_write_dir) \n",
    "vegm = read_clm('/home/at8471/subset_pfensemble_wf/create_ensembles/inputs/datacatalog_test1_conus1_2006WY/static/drv_vegm.dat', type = 'vegm')\n",
    "\n",
    "land_cover_vegm = np.zeros((vegm.shape[0], vegm.shape[1]))\n",
    "mult = 0\n",
    "\n",
    "for i in range(5,23):\n",
    "\n",
    "    mult = mult + 1\n",
    "    land_cover_vegm = land_cover_vegm + vegm[:,:,i] * mult\n",
    "\n",
    "plt.imshow(land_cover_vegm, origin='lower', interpolation=None)\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832bc4a",
   "metadata": {},
   "source": [
    "#### Check climate forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e47906",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(forcing_dir) \n",
    "test = read_pfb('NLDAS.APCP.003937_to_003960.pfb')\n",
    "test = test.max(axis = 0) #so we can check a var like precip\n",
    "\n",
    "sub_flip = np.zeros((1,nj,ni))\n",
    "sub_flip[0,:,:] = test[:,:]\n",
    "sub_flip = np.flip(sub_flip,1)\n",
    "plt.imshow(sub_flip[0,:,:], cmap=cmap1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be6023",
   "metadata": {},
   "source": [
    "### 8. Set up a baseline run from a reference yaml\n",
    "This function will return the correct template yaml file to do your run based on the grid, if you're doing spin-up and if you're using a solid file with the necessary keys changed to run your subset with selected climate forcing at baseline for one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_runscript_for_subset(ij_bounds, runscript_path = reference_run, write_dir = pf_out_dir, runname = runname, forcing_dir = forcing_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf102c",
   "metadata": {},
   "source": [
    "### 9. Copy over your static files to your run directory\n",
    "As a seperate function as you may only need to do this once, or you may want to copy subset static files to different run directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_static_files(static_input_dir = static_write_dir, pf_dir = pf_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31c77a",
   "metadata": {},
   "source": [
    "### 10. Change the file names in your runscript if desired\n",
    "If you have changed the name of a static input file either from those used in the reference yamls provided on X GitHub repo, or have changed the name of an individual file for an ensemble or other experiment, you can change it with this function by providing the target runscript (yaml or pfidb) and the new file name(s) as an arguments. Only those arguments with a specified file name will be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_filename_values(runscript_path = target_runscript, ip = \"conus1_baseline_mod_2005.09.30:23.00.00_UTC0_press.pfb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564141e",
   "metadata": {},
   "source": [
    "### 11. Change processor topolgoy if desired and then distribute your inputs and forcings to match the new topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3de06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_run(P=P, Q=Q, runscript_path = target_runscript, pf_run_dir = pf_out_dir, dist_clim_forcing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872dd2a",
   "metadata": {},
   "source": [
    "### 12. Do a baseline run.\n",
    "Load in the yaml run file you've created which is in the same folder as your static forcings and points to your desired Climate forcings. This assumes you do not want to make any changes from the parent model you used (Ex. conus1 baseline) and will run your subset at baseline conditions. Outputs should be almost identical to the parent model at your subset location for the same time period if you make no additional changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8d5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_working_directory(f'{pf_out_dir}')\n",
    "print(pf_out_dir)\n",
    "\n",
    "#load the specified run script\n",
    "run = Run.from_definition(target_runscript)\n",
    "print(f\"Loaded run with runname: {run.get_name()}\")\n",
    "\n",
    "# The following line is setting the run just for 10 hours for testing purposes\n",
    "run.TimingInfo.StopTime = 10\n",
    "\n",
    "#Need to set --ntasks='num_procs' (16 for 4x4) when starting notebook, request 1 core\n",
    "run.run(working_directory=pf_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0c767",
   "metadata": {},
   "source": [
    "### 13. Restart a parflow run\n",
    "If you need to restart a run to complete a spinup, transient run, etc then you can run the following to make the necessary updates to your runscript and then overwrite it in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restart_run(target_runscript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
